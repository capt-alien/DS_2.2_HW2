{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2\n",
    "\n",
    "Build and train a MLP Model to classify Mnist dataset\n",
    "\n",
    "1- MLP Network accepts 1D data. So we should flatten our 2D image, then print the dimension of the result arrays.\n",
    "\n",
    "2- Normalize data by rescaling them to (0,1)\n",
    "\n",
    "3- Convert label arrays to 1-hot representation (keras.utils.to_categorical)\n",
    "\n",
    "4- Define Model\n",
    "\n",
    "Hidden Layer 1: Fully Conncted + Relu Activition (e.g. 512 Nuerons)\n",
    "Hidden Layer 2: Fully Connected + Relu Activition (e.g. 512 Neurons)\n",
    "Outout Layer: Fully Connected + Softmax Activition\n",
    "Build and train a CNN+MLP deep learning model with Keras with followings specs for MNIST dataset:\n",
    "\n",
    "Conv2D(32, kernel_size=(3, 3), activation='relu')\n",
    "Conv2D(64, kernel_size=(3, 3), activation='relu')\n",
    "MaxPooling2D(pool_size=(2, 2))\n",
    "Dense(128, activation='relu')\n",
    "Dense(num_classes, activation='softmax')\n",
    "\n",
    "Also build another model with BatchNormalization and Dropout. Compare these two CNN + MLP models performance for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMport libaries\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mnist:\n",
    "https://github.com/Make-School-Courses/DS-2.2-Deep-Learning/blob/master/Lessons/ConvolutionalNeuralNetwork.md\n",
    "\n",
    "MLP:\n",
    "https://github.com/Make-School-Courses/DS-2.2-Deep-Learning/blob/master/Lessons/WhatisNeuralNetwork.md\n",
    "\n",
    "Alan/Justin MLP\n",
    "https://github.com/JSitter/DS-3-Deep-Learning/blob/master/notebooks/MultilayerPerceptrons.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMport MLP dataset\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- MLP Network accepts 1D data. So we should flatten our 2D image, then print the dimension of the result arrays.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label for image: 5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[55])\n",
    "print(\"label for image: {}\".format(y_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (60000, 28, 28)\n",
      "Shape of X_test: (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of X_train: {}\".format(X_train.shape))\n",
    "print(\"Shape of X_test: {}\".format(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reshape each image into vectors of Pixel Values\n",
    "\n",
    "X_train = X_train.reshape(60000, 784).astype(\"float32\")\n",
    "X_test = X_test.reshape(10000, 784).astype(\"float32\")\n",
    "\n",
    "display(y_train[1])\n",
    "display(y_train.shape)\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2- Normalize data by rescaling them to (0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255.0\n",
      "255.0\n"
     ]
    }
   ],
   "source": [
    "print(X_train.max())\n",
    "print(X_test.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train /= 255.0\n",
    "X_test /= 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(X_train.max())\n",
    "print(X_test.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3- Convert label arrays to 1-hot representation (keras.utils.to_categorical)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4- Define Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
